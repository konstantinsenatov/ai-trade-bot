#!/usr/bin/env python3
"""
–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è TODO.md –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞–Ω–∞–ª–∏–∑–∞ –∫–æ–¥–∞, —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –±—ç–∫—Ç–µ—Å—Ç–æ–≤ –∏ —Ç–µ—Å—Ç–æ–≤.

–ò—Å—Ç–æ—á–Ω–∏–∫–∏ –∑–∞–¥–∞—á:
- –ú–∞—Ä–∫–µ—Ä—ã TODO/FIXME/NOTE –≤ –∫–æ–¥–µ
- –ê–Ω–∞–ª–∏–∑ CSV —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –±—ç–∫—Ç–µ—Å—Ç–æ–≤
- JUnit –æ—Ç—á—ë—Ç—ã —Ç–µ—Å—Ç–æ–≤
"""

import csv
import re
import xml.etree.ElementTree as ET
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Tuple, Optional


def scan_code_markers(project_root: Path) -> List[Tuple[str, int, str]]:
    """
    –°–∫–∞–Ω–∏—Ä—É–µ—Ç –≤—Å–µ —Ñ–∞–π–ª—ã –ø—Ä–æ–µ–∫—Ç–∞ –Ω–∞ –Ω–∞–ª–∏—á–∏–µ –º–∞—Ä–∫–µ—Ä–æ–≤ TODO/FIXME/NOTE.
    
    Args:
        project_root: –ö–æ—Ä–Ω–µ–≤–∞—è –ø–∞–ø–∫–∞ –ø—Ä–æ–µ–∫—Ç–∞
        
    Returns:
        –°–ø–∏—Å–æ–∫ –∫–æ—Ä—Ç–µ–∂–µ–π (—Ñ–∞–π–ª, —Å—Ç—Ä–æ–∫–∞, —Ç–µ–∫—Å—Ç)
    """
    markers = []
    extensions = {'.py', '.md', '.yml', '.yaml', '.sh'}
    
    # –ü–∞—Ç—Ç–µ—Ä–Ω –¥–ª—è –ø–æ–∏—Å–∫–∞ –º–∞—Ä–∫–µ—Ä–æ–≤
    pattern = re.compile(r'(TODO|FIXME|NOTE):\s*(.+)', re.IGNORECASE)
    
    for file_path in project_root.rglob('*'):
        if file_path.is_file() and file_path.suffix.lower() in extensions:
            try:
                with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                    for line_num, line in enumerate(f, 1):
                        match = pattern.search(line)
                        if match:
                            marker_type = match.group(1).upper()
                            text = match.group(2).strip()
                            relative_path = file_path.relative_to(project_root)
                            markers.append((str(relative_path), line_num, f"{marker_type}: {text}"))
            except Exception as e:
                print(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞ {file_path}: {e}")
                continue
    
    return markers


def find_backtest_csvs(project_root: Path) -> List[Path]:
    """
    –ù–∞—Ö–æ–¥–∏—Ç –≤—Å–µ CSV —Ñ–∞–π–ª—ã —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –±—ç–∫—Ç–µ—Å—Ç–æ–≤.
    
    Args:
        project_root: –ö–æ—Ä–Ω–µ–≤–∞—è –ø–∞–ø–∫–∞ –ø—Ä–æ–µ–∫—Ç–∞
        
    Returns:
        –°–ø–∏—Å–æ–∫ –ø—É—Ç–µ–π –∫ CSV —Ñ–∞–π–ª–∞–º
    """
    csv_files = []
    search_paths = [
        project_root / "artifacts" / "backtests",
        project_root / "results" / "backtests", 
        project_root / "artifacts",
        project_root / "user_data"  # –î–æ–±–∞–≤–ª—è–µ–º –ø–∞–ø–∫—É —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏
    ]
    
    for search_path in search_paths:
        if search_path.exists():
            for csv_file in search_path.glob("*.csv"):
                csv_files.append(csv_file)
    
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –≤—Ä–µ–º–µ–Ω–∏ –º–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏–∏ (–Ω–æ–≤—ã–µ —Å–Ω–∞—á–∞–ª–∞)
    csv_files.sort(key=lambda x: x.stat().st_mtime, reverse=True)
    
    return csv_files


def analyze_backtests(csv_files: List[Path]) -> Tuple[List[Dict], List[Dict]]:
    """
    –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç CSV —Ñ–∞–π–ª—ã —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –±—ç–∫—Ç–µ—Å—Ç–æ–≤.
    
    Args:
        csv_files: –°–ø–∏—Å–æ–∫ –ø—É—Ç–µ–π –∫ CSV —Ñ–∞–π–ª–∞–º
        
    Returns:
        –ö–æ—Ä—Ç–µ–∂ (–∞–ª–µ—Ä—Ç—ã, –ª—É—á—à–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã)
    """
    alerts = []
    best_results = []
    
    for csv_file in csv_files:
        try:
            with open(csv_file, 'r', encoding='utf-8') as f:
                reader = csv.DictReader(f)
                
                for row in reader:
                    # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Å—Ç—Ä–æ–∫–∏ –±–µ–∑ –¥–∞–Ω–Ω—ã—Ö
                    if not row.get('mode') or not row.get('trades'):
                        continue
                    
                    # –ò–∑–≤–ª–µ–∫–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏
                    try:
                        trades = int(row.get('trades', 0))
                        equity = float(row.get('final_equity', 0))
                        winrate = float(row.get('win_rate', 0)) if row.get('win_rate') else 0
                        pf = float(row.get('pf', 0)) if row.get('pf') else 0
                        dd = float(row.get('max_dd', 0)) if row.get('max_dd') else 0
                        return_pct = float(row.get('return_pct', 0)) if row.get('return_pct') else 0
                        
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —É—Å–ª–æ–≤–∏—è –¥–ª—è –∞–ª–µ—Ä—Ç–æ–≤
                        if pf < 1.1 and pf > 0:
                            alerts.append({
                                'file': csv_file.name,
                                'mode': row.get('mode', 'unknown'),
                                'pf': pf,
                                'reason': f'–ù–∏–∑–∫–∏–π PF: {pf:.3f}'
                            })
                        
                        if winrate < 0.45 and winrate > 0:
                            alerts.append({
                                'file': csv_file.name,
                                'mode': row.get('mode', 'unknown'),
                                'winrate': winrate,
                                'reason': f'–ù–∏–∑–∫–∞—è win rate: {winrate:.1%}'
                            })
                        
                        if dd > 0.3:
                            alerts.append({
                                'file': csv_file.name,
                                'mode': row.get('mode', 'unknown'),
                                'dd': dd,
                                'reason': f'–í—ã—Å–æ–∫–∏–π drawdown: {dd:.1%}'
                            })
                        
                        if trades == 0:
                            alerts.append({
                                'file': csv_file.name,
                                'mode': row.get('mode', 'unknown'),
                                'trades': trades,
                                'reason': '–ù–µ—Ç —Å–¥–µ–ª–æ–∫'
                            })
                        
                        # –°–æ–±–∏—Ä–∞–µ–º –ª—É—á—à–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ PF
                        if pf > 1.0:
                            best_results.append({
                                'file': csv_file.name,
                                'mode': row.get('mode', 'unknown'),
                                'pf': pf,
                                'equity': equity,
                                'trades': trades,
                                'winrate': winrate,
                                'dd': dd,
                                'return_pct': return_pct
                            })
                    
                    except (ValueError, TypeError) as e:
                        print(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ —Å—Ç—Ä–æ–∫–∏ –≤ {csv_file}: {e}")
                        continue
        
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è CSV —Ñ–∞–π–ª–∞ {csv_file}: {e}")
            continue
    
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ª—É—á—à–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ PF
    best_results.sort(key=lambda x: x['pf'], reverse=True)
    
    return alerts, best_results


def parse_junit(junit_path: Path) -> List[Dict]:
    """
    –ü–∞—Ä—Å–∏—Ç JUnit XML —Ñ–∞–π–ª –∏ –∏–∑–≤–ª–µ–∫–∞–µ—Ç –æ—à–∏–±–∫–∏ –∏ —Ñ–µ–π–ª—ã.
    
    Args:
        junit_path: –ü—É—Ç—å –∫ JUnit XML —Ñ–∞–π–ª—É
        
    Returns:
        –°–ø–∏—Å–æ–∫ –æ—à–∏–±–æ–∫ –∏ —Ñ–µ–π–ª–æ–≤
    """
    failures: list[dict] = []
    
    if not junit_path.exists():
        return failures
    
    try:
        tree = ET.parse(junit_path)
        root = tree.getroot()
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ç–µ—Å—Ç-–∫–µ–π—Å—ã
        for testcase in root.findall('.//testcase'):
            name = testcase.get('name', 'unknown')
            classname = testcase.get('classname', 'unknown')
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –æ—à–∏–±–∫–∏
            error = testcase.find('error')
            if error is not None:
                message = error.get('message', '–û—à–∏–±–∫–∞')
                failures.append({
                    'type': 'ERROR',
                    'test': f"{classname}.{name}",
                    'message': message
                })
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ —Ñ–µ–π–ª—ã
            failure = testcase.find('failure')
            if failure is not None:
                message = failure.get('message', '–§–µ–π–ª')
                failures.append({
                    'type': 'FAILURE',
                    'test': f"{classname}.{name}",
                    'message': message
                })
    
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JUnit —Ñ–∞–π–ª–∞ {junit_path}: {e}")
    
    return failures


def render_markdown(
    code_markers: List[Tuple[str, int, str]],
    backtest_alerts: List[Dict],
    best_results: List[Dict],
    test_failures: List[Dict]
) -> str:
    """
    –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç Markdown —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –¥–ª—è TODO.md.
    
    Args:
        code_markers: –ú–∞—Ä–∫–µ—Ä—ã –∏–∑ –∫–æ–¥–∞
        backtest_alerts: –ê–ª–µ—Ä—Ç—ã –∏–∑ –±—ç–∫—Ç–µ—Å—Ç–æ–≤
        best_results: –õ—É—á—à–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        test_failures: –û—à–∏–±–∫–∏ —Ç–µ—Å—Ç–æ–≤
        
    Returns:
        Markdown —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ
    """
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    
    lines = [
        f"# TODO (auto-generated) ‚Äî {timestamp}",
        "",
        "## üö® Test Failures",
        ""
    ]
    
    if test_failures:
        for failure in test_failures:
            lines.append(f"- [ ] **{failure['type']}**: {failure['test']} ‚Äî {failure['message']}")
    else:
        lines.append("- [ ] –ù–µ—Ç –æ—à–∏–±–æ–∫ —Ç–µ—Å—Ç–æ–≤")
    
    lines.extend([
        "",
        "## üìâ Backtest Alerts",
        ""
    ])
    
    if backtest_alerts:
        for alert in backtest_alerts:
            lines.append(f"- [ ] **{alert['mode']}** ({alert['file']}): {alert['reason']}")
    else:
        lines.append("- [ ] –ù–µ—Ç –∞–ª–µ—Ä—Ç–æ–≤ –±—ç–∫—Ç–µ—Å—Ç–æ–≤")
    
    lines.extend([
        "",
        "## üìà Suggestions from Results",
        ""
    ])
    
    if best_results:
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ø-3 –ª—É—á—à–∏—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
        for i, result in enumerate(best_results[:3], 1):
            lines.append(f"- [ ] **#{i}** {result['mode']} (PF: {result['pf']:.3f}, Equity: {result['equity']:.0f}, Trades: {result['trades']})")
    else:
        lines.append("- [ ] –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")
    
    lines.extend([
        "",
        "## üõ† Code Markers (TODO/FIXME/NOTE)",
        ""
    ])
    
    if code_markers:
        for file_path, line_num, text in code_markers:
            lines.append(f"- [ ] `{file_path}:{line_num}` ‚Äî {text}")
    else:
        lines.append("- [ ] –ù–µ—Ç –º–∞—Ä–∫–µ—Ä–æ–≤ –≤ –∫–æ–¥–µ")
    
    lines.append("")
    
    return "\n".join(lines)


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Å–∫—Ä–∏–ø—Ç–∞."""
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–æ—Ä–Ω–µ–≤—É—é –ø–∞–ø–∫—É –ø—Ä–æ–µ–∫—Ç–∞
    script_dir = Path(__file__).parent
    project_root = script_dir.parent
    
    print(f"–ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–µ–∫—Ç–∞: {project_root}")
    print("–°–∫—Ä–∏–ø—Ç –∑–∞–ø—É—â–µ–Ω —É—Å–ø–µ—à–Ω–æ")
    
    # 1. –°–∫–∞–Ω–∏—Ä—É–µ–º –º–∞—Ä–∫–µ—Ä—ã –≤ –∫–æ–¥–µ
    print("–°–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –º–∞—Ä–∫–µ—Ä–æ–≤ –≤ –∫–æ–¥–µ...")
    code_markers = scan_code_markers(project_root)
    print(f"–ù–∞–π–¥–µ–Ω–æ –º–∞—Ä–∫–µ—Ä–æ–≤: {len(code_markers)}")
    
    # 2. –ù–∞—Ö–æ–¥–∏–º CSV —Ñ–∞–π–ª—ã —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –±—ç–∫—Ç–µ—Å—Ç–æ–≤
    print("–ü–æ–∏—Å–∫ CSV —Ñ–∞–π–ª–æ–≤ —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –±—ç–∫—Ç–µ—Å—Ç–æ–≤...")
    csv_files = find_backtest_csvs(project_root)
    print(f"–ù–∞–π–¥–µ–Ω–æ CSV —Ñ–∞–π–ª–æ–≤: {len(csv_files)}")
    
    # 3. –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –±—ç–∫—Ç–µ—Å—Ç–æ–≤
    print("–ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –±—ç–∫—Ç–µ—Å—Ç–æ–≤...")
    backtest_alerts, best_results = analyze_backtests(csv_files)
    print(f"–ù–∞–π–¥–µ–Ω–æ –∞–ª–µ—Ä—Ç–æ–≤: {len(backtest_alerts)}")
    print(f"–ù–∞–π–¥–µ–Ω–æ –ª—É—á—à–∏—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {len(best_results)}")
    
    # 4. –ü–∞—Ä—Å–∏–º JUnit –æ—Ç—á—ë—Ç—ã
    print("–ü–æ–∏—Å–∫ JUnit –æ—Ç—á—ë—Ç–æ–≤...")
    junit_paths = [
        project_root / "artifacts" / "tests" / "junit.xml",
        project_root / "reports" / "junit.xml"
    ]
    
    test_failures: list[dict] = []
    for junit_path in junit_paths:
        if junit_path.exists():
            print(f"–ü–∞—Ä—Å–∏–Ω–≥ JUnit —Ñ–∞–π–ª–∞: {junit_path}")
            failures: list[dict] = parse_junit(junit_path)
            test_failures.extend(failures)
    
    print(f"–ù–∞–π–¥–µ–Ω–æ –æ—à–∏–±–æ–∫ —Ç–µ—Å—Ç–æ–≤: {len(test_failures)}")
    
    # 5. –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º Markdown
    print("–ì–µ–Ω–µ—Ä–∞—Ü–∏—è TODO.md...")
    markdown_content = render_markdown(
        code_markers, backtest_alerts, best_results, test_failures
    )
    
    # 6. –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –≤ —Ñ–∞–π–ª
    todo_path = project_root / "TODO.md"
    try:
        with open(todo_path, 'w', encoding='utf-8') as f:
            f.write(markdown_content)
        print(f"TODO.md —É—Å–ø–µ—à–Ω–æ —Å–æ–∑–¥–∞–Ω: {todo_path}")
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –∑–∞–ø–∏—Å–∏ TODO.md: {e}")
        return 1
    
    # 7. –í—ã–≤–æ–¥–∏–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
    print("\n=== –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ ===")
    print(f"–ú–∞—Ä–∫–µ—Ä—ã –≤ –∫–æ–¥–µ: {len(code_markers)}")
    print(f"CSV —Ñ–∞–π–ª—ã: {len(csv_files)}")
    print(f"–ê–ª–µ—Ä—Ç—ã –±—ç–∫—Ç–µ—Å—Ç–æ–≤: {len(backtest_alerts)}")
    print(f"–õ—É—á—à–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã: {len(best_results)}")
    print(f"–û—à–∏–±–∫–∏ —Ç–µ—Å—Ç–æ–≤: {len(test_failures)}")
    
    return 0


if __name__ == "__main__":
    exit(main())